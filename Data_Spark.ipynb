{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9767da-6c16-4d2d-aef8-ba6b8c363634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the dataset from the file\n",
    "file_path = r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Customers.csv\"\n",
    "data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "#birthdayin current given format\n",
    "# List of potential date formats for parsing\n",
    "date_formats_list = ['%d-%m-%Y', '%m/%d/%Y', '%d/%m/%Y', '%m-%d-%Y']\n",
    "\n",
    "# Function to handle date parsing\n",
    "def convert_to_date(date_text):\n",
    "    for pattern in date_formats_list:\n",
    "        try:\n",
    "            return pd.to_datetime(date_text, format=pattern)\n",
    "        except ValueError:\n",
    "            pass  # If one format fails, move to the next\n",
    "    return pd.NaT  # Return NaT if no formats match\n",
    "\n",
    "data['Birthday'] = data['Birthday'].apply(convert_to_date)\n",
    "data['Birthday'] = data['Birthday'].apply(lambda date: date.strftime('%d-%m-%Y') if pd.notnull(date) else 'None')\n",
    "\n",
    "#calculating AGE \n",
    "# Ensure 'Birthday' is in datetime format\n",
    "data['Birthday'] = pd.to_datetime(data['Birthday'], format='%d-%m-%Y', errors='coerce')\n",
    "# Calculate age based on the current date\n",
    "current_year = datetime.now().year\n",
    "data['Age'] = data['Birthday'].apply(lambda birth_date: current_year - birth_date.year if pd.notnull(birth_date) else None)\n",
    "\n",
    "\n",
    "# Fill missing values in the State Code column with a placeholder\n",
    "data['State Code'] = data['State Code'].fillna('NAP')\n",
    "\n",
    "\n",
    "# Save the cleaned dataset to a new file\n",
    "output_file = r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Processed_Customers.csv\"\n",
    "data.to_csv(output_file, index=False)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4559e-d723-4167-bcc8-769a1878cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file location and load the dataset\n",
    "input_file = r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Products.csv\"\n",
    "data = pd.read_csv(input_file, encoding='ISO-8859-1')\n",
    "\n",
    "# Clean monetary columns by removing unwanted characters\n",
    "data['Unit Cost USD'] = data['Unit Cost USD'].replace({r'\\$': '', ',': ''}, regex=True).str.strip()\n",
    "data['Unit Price USD'] = data['Unit Price USD'].replace({r'\\$': '', ',': ''}, regex=True).str.strip()\n",
    "\n",
    "# Convert cleaned columns to numeric types\n",
    "data['Unit Cost USD'] = pd.to_numeric(data['Unit Cost USD'], errors='coerce')\n",
    "data['Unit Price USD'] = pd.to_numeric(data['Unit Price USD'], errors='coerce')\n",
    "\n",
    "# Export the processed data to a new CSV file\n",
    "output_file = r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Processed_Products.csv\"\n",
    "data.to_csv(output_file, index=False)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d376361-ee2e-46fb-8b3a-e5075a82e886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "df = pd.read_csv(r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Sales.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "# List of potential date formats for parsing\n",
    "date_formats_list = ['%d-%m-%Y', '%m/%d/%Y', '%d/%m/%Y', '%m-%d-%Y']\n",
    "\n",
    "# Function to handle date parsing\n",
    "def parse_dates(date_text):\n",
    "    for pattern in date_formats_list:\n",
    "        try:\n",
    "            return pd.to_datetime(date_text, format=pattern)\n",
    "        except ValueError:\n",
    "            pass  # If one format fails, move to the next\n",
    "    return pd.NaT  # Return NaT if no formats match\n",
    "\n",
    "# Apply the parsing function to the 'date' column\n",
    "df['Order Date'] = df['Order Date'].apply(parse_dates)\n",
    "df['Delivery Date'] = df['Delivery Date'].apply(parse_dates)\n",
    "\n",
    "df['Order Date'] = df['Order Date'].dt.strftime('%d-%m-%Y')\n",
    "df['Delivery Date'] = df['Delivery Date'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "df.dropna(subset=['Delivery Date'], inplace=True)\n",
    "df.isnull().sum()\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "# Convert the dates to datetime format\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d-%m-%Y')\n",
    "df['Delivery Date'] = pd.to_datetime(df['Delivery Date'], format='%d-%m-%Y')\n",
    "# Filter out rows where Delivery_Date is earlier than Order_Date\n",
    "df = df[df['Delivery Date'] >= df['Order Date']]\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "Output_path = r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Processed_Sales.csv\"\n",
    "df.to_csv(Output_path, index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c4df64-47a5-43ad-8c14-ca3749cfbd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Stores.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "# Define possible date formats\n",
    "date_formats = ['%d-%m-%Y', '%m/%d/%Y']\n",
    "\n",
    "def parse_dates(date_str): \n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt) \n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT  # Return NaT if no format matches\n",
    "\n",
    "# Apply the parsing function to the 'Open Date' column\n",
    "df['Open Date'] = df['Open Date'].apply(parse_dates)\n",
    "\n",
    "# Convert to the desired format using apply (replaces .dt.strftime)\n",
    "df['Open Date'] = df['Open Date'].apply(lambda x: x.strftime('%d-%m-%Y') if pd.notna(x) else x)\n",
    "\n",
    "# Fill missing values in 'Square Meters' with 0\n",
    "df['Square Meters'] = df['Square Meters'].fillna(0)\n",
    "\n",
    "# Output the processed data to a new CSV file\n",
    "Output_path = r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Processed_Stores.csv\"\n",
    "df.to_csv(Output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e0ca9d-823b-4a72-ab58-80311be87aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Exchange_Rates.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "date_formats = ['%d-%m-%Y', '%m/%d/%Y'] #date format available in my file\n",
    "\n",
    "def parse_dates(date_str): \n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt) \n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT #print not a time\n",
    "\n",
    "# Apply the parsing function to the 'date' column\n",
    "df['Date'] = df['Date'].apply(parse_dates)\n",
    "\n",
    "# Convert to the desired format\n",
    "df['Date'] = df['Date'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "Output_path = r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Processed_Exchange_Rates.csv\"\n",
    "df.to_csv(Output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d06d0-da72-4fe7-a807-24c110d83a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c161d5a-2a97-42c0-99ef-e311c5d94028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Date dtype in df2: object\n",
      "Date dtype in df4: object\n",
      "   CustomerKey  Gender           Name            City State Code  \\\n",
      "0          301  Female  Lilly Harding  WANDEARAH EAST         SA   \n",
      "1          301  Female  Lilly Harding  WANDEARAH EAST         SA   \n",
      "2          301  Female  Lilly Harding  WANDEARAH EAST         SA   \n",
      "3          301  Female  Lilly Harding  WANDEARAH EAST         SA   \n",
      "4          301  Female  Lilly Harding  WANDEARAH EAST         SA   \n",
      "\n",
      "           State_x Zip Code  Country_x  Continent    Birthday  ...  \\\n",
      "0  South Australia     5523  Australia  Australia  1939-07-03  ...   \n",
      "1  South Australia     5523  Australia  Australia  1939-07-03  ...   \n",
      "2  South Australia     5523  Australia  Australia  1939-07-03  ...   \n",
      "3  South Australia     5523  Australia  Australia  1939-07-03  ...   \n",
      "4  South Australia     5523  Australia  Australia  1939-07-03  ...   \n",
      "\n",
      "     Subcategory  CategoryKey  Category Country_y State_y  Square Meters  \\\n",
      "0  Recording Pen            1     Audio    Online  Online            0.0   \n",
      "1  Recording Pen            1     Audio    Online  Online            0.0   \n",
      "2  Recording Pen            1     Audio    Online  Online            0.0   \n",
      "3  Recording Pen            1     Audio    Online  Online            0.0   \n",
      "4  Recording Pen            1     Audio    Online  Online            0.0   \n",
      "\n",
      "    Open Date       Date Currency Exchange  \n",
      "0  01-01-2010 2019-11-11      USD   1.0000  \n",
      "1  01-01-2010 2019-11-11      CAD   1.3230  \n",
      "2  01-01-2010 2019-11-11      AUD   1.4587  \n",
      "3  01-01-2010 2019-11-11      EUR   0.9057  \n",
      "4  01-01-2010 2019-11-11      GBP   0.7766  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "Index(['CustomerKey', 'Gender', 'Name', 'City', 'State Code', 'State_x',\n",
      "       'Zip Code', 'Country_x', 'Continent', 'Birthday', 'Age', 'Order Number',\n",
      "       'Line Item', 'Order Date', 'Delivery Date', 'StoreKey', 'ProductKey',\n",
      "       'Quantity', 'Currency Code', 'Product Name', 'Brand', 'Color',\n",
      "       'Unit Cost USD', 'Unit Price USD', 'SubcategoryKey', 'Subcategory',\n",
      "       'CategoryKey', 'Category', 'Country_y', 'State_y', 'Square Meters',\n",
      "       'Open Date', 'Date', 'Currency', 'Exchange'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Processed_Customers.csv\")\n",
    "df1 = pd.read_csv(r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Processed_Products.csv\")\n",
    "df2 = pd.read_csv(r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Processed_Sales.csv\")\n",
    "df3 = pd.read_csv(r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Processed_Stores.csv\")\n",
    "df4 = pd.read_csv(r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Processed_Exchange_Rates.csv\")\n",
    "\n",
    "print(\"Order Date dtype in df2:\", df2['Order Date'].dtype)\n",
    "print(\"Date dtype in df4:\", df4['Date'].dtype)\n",
    "\n",
    "df2['Order Date'] = pd.to_datetime(df2['Order Date'], errors='coerce')  # Convert to datetime\n",
    "df4['Date'] = pd.to_datetime(df4['Date'], errors='coerce')  # Convert to datetime\n",
    "\n",
    "\n",
    "# Merge df and df2\n",
    "merged_df = pd.merge(df, df2, on='CustomerKey', how='inner')\n",
    "\n",
    "\n",
    "# Merge with df1\n",
    "if not merged_df.empty:\n",
    "    merged_df = pd.merge(merged_df, df1, on='ProductKey', how='inner')\n",
    "    \n",
    "\n",
    "# Merge with df3\n",
    "if not merged_df.empty:\n",
    "    merged_df = pd.merge(merged_df, df3, on='StoreKey', how='inner')\n",
    "    \n",
    "\n",
    "# Merge with df4\n",
    "if not merged_df.empty:\n",
    "    merged_df = pd.merge(merged_df, df4, left_on='Order Date', right_on='Date', how='inner')\n",
    "    \n",
    "print(merged_df.head()) #for verifying the joins\n",
    "\n",
    "print(merged_df.columns) #for all coulumn names\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "merged_df.drop(columns=['State_y', 'Country_y', 'Date'], inplace=True)\n",
    "merged_df.rename(columns={'State_x': 'State', 'Country_x': 'Country'}, inplace=True)\n",
    "\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "Output_path = r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Data_Spark.csv\"\n",
    "merged_df.to_csv(Output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb037282-e457-4a64-b9a3-d7dd8a85c122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25370 entries, 0 to 25369\n",
      "Data columns (total 32 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   CustomerKey     25370 non-null  int64  \n",
      " 1   Gender          25370 non-null  object \n",
      " 2   Name            25370 non-null  object \n",
      " 3   City            25370 non-null  object \n",
      " 4   State Code      25370 non-null  object \n",
      " 5   State           25370 non-null  object \n",
      " 6   Zip Code        25370 non-null  object \n",
      " 7   Country         25370 non-null  object \n",
      " 8   Continent       25370 non-null  object \n",
      " 9   Birthday        25370 non-null  object \n",
      " 10  Age             25370 non-null  int64  \n",
      " 11  Order Number    25370 non-null  int64  \n",
      " 12  Line Item       25370 non-null  int64  \n",
      " 13  Order Date      25370 non-null  object \n",
      " 14  Delivery Date   25370 non-null  object \n",
      " 15  StoreKey        25370 non-null  int64  \n",
      " 16  ProductKey      25370 non-null  int64  \n",
      " 17  Quantity        25370 non-null  int64  \n",
      " 18  Currency Code   25370 non-null  object \n",
      " 19  Product Name    25370 non-null  object \n",
      " 20  Brand           25370 non-null  object \n",
      " 21  Color           25370 non-null  object \n",
      " 22  Unit Cost USD   25370 non-null  float64\n",
      " 23  Unit Price USD  25370 non-null  float64\n",
      " 24  SubcategoryKey  25370 non-null  int64  \n",
      " 25  Subcategory     25370 non-null  object \n",
      " 26  CategoryKey     25370 non-null  int64  \n",
      " 27  Category        25370 non-null  object \n",
      " 28  Square Meters   25370 non-null  float64\n",
      " 29  Open Date       25370 non-null  object \n",
      " 30  Currency        25370 non-null  object \n",
      " 31  Exchange        25370 non-null  float64\n",
      "dtypes: float64(4), int64(9), object(19)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mysql import connector\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Connect to SQL server\n",
    "connection = connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    port=3306,\n",
    "    password=\"123456789\",\n",
    "    connection_timeout=600 # Timeout after 600 seconds\n",
    ")\n",
    "mycursor = connection.cursor()\n",
    "\n",
    "\n",
    "#Database Selection\n",
    "mycursor.execute(\"CREATE DATABASE IF NOT EXISTS dataspark\")\n",
    "mycursor.execute(\"USE dataspark\")\n",
    "\n",
    "\n",
    "# Load CSV data\n",
    "df = pd.read_csv(r\"C:\\Users\\ashwi\\GUVI_Projects\\EDA\\Data_Spark.csv\", low_memory=False)\n",
    "\n",
    "df = df.dropna()  # Drop null values\n",
    "df.info()\n",
    "# Replace data types from pandas to MySQL\n",
    "a = \",\".join(f\"`{i}` {j}\" for i, j in zip(df.columns, df.dtypes)).replace(\"float64\", \"FLOAT\").replace(\"object\", \"TEXT\").replace(\"int64\", \"INT\")\n",
    "# Use a valid table name\n",
    "table_name = \"Data Spark\"\n",
    "\n",
    "# Create the table\n",
    "create_table_query = f\"CREATE TABLE IF NOT EXISTS`{table_name}` ({a})\"\n",
    "with connection.cursor() as cursor:\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "# Insert data into the table\n",
    "for i in range(len(df)):\n",
    "    insert_query = f\"INSERT INTO `{table_name}` VALUES {tuple(df.iloc[i])}\"\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(insert_query)\n",
    "    connection.commit()\n",
    "\n",
    "\n",
    "\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
